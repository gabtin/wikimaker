---
author: gabriele-tinelli
last_updated: '2026-02-16T14:51:25.931887+00:00'
sources:
- https://gabtin.github.io/thoughts/robotics-foundation-models/
title: Language as Interface, Not Foundation
---

## Overview

The concept **"Language as Interface, Not Foundation"** is a design principle in artificial intelligence and robotics, notably discussed by researcher Gabriele Tinelli. It argues that language should function as a supplementary communication layer built atop a core system grounded in physical intuition and experience, rather than serving as the primary basis for cognition or reasoning. This approach emphasizes robustness and reliability by ensuring that systems understand fundamental physical concepts before using language to describe them.

## Core Principles

Tinelli's concept challenges the tendency in some AI research to treat language as a foundational framework for knowledge. Instead, it posits that true understanding arises from direct interaction with the physical world. A system should first develop non-linguistic representations of concepts like object permanence, force, spatial relationships, and causality through sensory-motor experiences. Language then acts as a mapping tool to label and communicate these pre-existing concepts.

> "It doesn't use words to think; it uses words to label the concepts it already physically understands."

This principle aligns with theories of embodied cognition, suggesting that intelligence is rooted in an agent's body and its interactions with the environment. By prioritizing a physically intuitive foundation, the system avoids the pitfalls of abstract symbolic reasoning disconnected from reality.

## Application in Robotic Systems

In robotics, applying this principle involves designing architectures where perception, action, and low-level reasoning are based on continuous interaction with the environment. For instance, a robot might learn about stability or containment through manipulation, forming internal models that guide its behavior. Natural language processing capabilities are added as an interface layer, allowing the robot to interpret commands or generate descriptions based on its grounded models.

Tinelli contends that this methodology leads to more resilient and adaptable robots. When language is merely an interface, the system remains functional even if linguistic processing fails or encounters ambiguities. The physical foundation provides a common-sense baseline that pure language models often lack.

> "Once they have that, the language layer becomes just a helpful interface, rather than the shaky foundation of the entire system."

This quote underscores the stability gained from this approach, contrasting it with systems that rely heavily on potentially unstable linguistic structures for core reasoning.

## Implications and Significance

The "Language as Interface, Not Foundation" concept has significant implications for AI safety and capability. It advocates for a shift away from building systems primarily on statistical language patterns, which can produce coherent text without deep understanding. Instead, it promotes hybrid models that combine embodied learning with linguistic interface, potentially leading to AI that demonstrates more reliable common-sense reasoning.

This perspective also informs debates on the limits of large language models (LLMs), suggesting they be integrated with robotics or simulation environments to ground their outputs. It highlights the importance of interdisciplinary research combining robotics, cognitive science, and linguistics to create more general and trustworthy intelligent agents.

## See Also

* Embodied cognition
* Grounded language acquisition
* Symbol grounding problem
* Intuitive physics in artificial intelligence
* Humanâ€“robot interaction

## Related Concepts

- [[VLA Limitations for Deployment]]