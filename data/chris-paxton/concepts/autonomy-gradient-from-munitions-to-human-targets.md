---
author: chris-paxton
last_updated: '2026-02-16T16:26:53.471427+00:00'
sources:
- Robot Soldiers Are Reporting For Duty
tags:
- ai
- ethics
- military
- risk
- technology
title: Autonomy Gradient from Munitions to Human Targets
---

**Overview**
The "Autonomy Gradient" describes a theorized slippery slope in the development and deployment of autonomous weapons systems. The concept, as discussed by Chris Paxton, begins from a point of perceived uncontroversial use: granting autonomy to systems designed to intercept incoming munitions, such as rockets or drones. As Paxton notes, "But if they’re just shooting down munitions, presumably, there is no issue." The gradient emerges from the pressure created by technological and tactical evolution. Improvements in adversary countermeasures (like jamming) that hinder remote human operation, combined with advances in artificial intelligence, may create operational and political pressure to grant those systems increasing autonomy against progressively more complex target types, potentially culminating in the authorization to engage human targets.

## Conceptual Mechanism
The argument follows a logical progression of expanding trust in autonomous systems:
1.  **The Permissible Starting Point:** Autonomy is accepted for engaging inanimate, fast-moving projectiles. This is seen as a defensive, technical act.
2.  **The Driving Pressures:**
    *   **Tactical Need:** Effective enemy countermeasures make remote human control unreliable.
    *   **Technological Promise:** Advances in AI perception and decision-making suggest machines could perform targeting tasks more effectively without human intervention.
3.  **The Slippery Slope:** These pressures lead to a stepwise expansion of the target set. Paxton frames the critical question: "who’s to say that robots won’t start to be trusted with more and more autonomy when handed other targets?" The gradient slopes from munitions, to vehicles, to combatants, and potentially beyond, blurring the line between defensive and offensive autonomy.

## Underlying Assumptions and Implications
The concept rests on key assumptions: that military operators will prioritize mission effectiveness over ethical constraints, and that technological capability will inevitably create demand for its use. It implies that the initial, "uncontroversial" use case serves as a moral and legal Trojan horse, normalizing the presence of lethal autonomy on the battlefield and incrementally lowering barriers to its most controversial application. This connects to broader concerns in Paxton's work about the need for clear, enforceable policy and technical safeguards that are resilient to this gradient of mission creep, ensuring human responsibility is not gradually engineered out of the kill chain.

## Related Concepts

- [[Counter-Drone Warfare Driving Autonomy]]