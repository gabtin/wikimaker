---
author: chris-paxton
last_updated: '2026-02-16T16:28:32.086199+00:00'
sources:
- How to Fake A Robotics Result
tags:
- bias
- ethics
- methodology
- research
title: Choosing Weak Baselines
---

The concept of **"Choosing Weak Baselines"** is a strategic, and cynical, approach to crafting a research paper's results section. It is based on the premise that while comparing your new model to existing work is essential, the selection of which existing work to compare against is a tactical decision. The goal is to ensure your method appears superior, not necessarily through genuine, overwhelming innovation, but by contrasting it against benchmarks known to be limited or flawed. This practice is exemplified by the suggestion to use models like **Octo**, which were highly publicized but had significant, under-discussed weaknesses.

## Key Points & Analysis

> "When working on the results section of your research paper or blog post, you may be tempted to include some baselines. This is a good idea; just be careful to choose weak baselines so you look good. Octo is a great choice here; it was well publicized but had lots of limitations that werenâ€™t widely discussed."

*   **The Strategy:** The advice explicitly frames baseline selection as a tool for **self-promotion** rather than for honest scientific benchmarking. The ideal candidate is a "weak baseline" that is nonetheless famous, providing name recognition while ensuring an easy comparison.
*   **Underlying Assumptions:** This concept assumes the research landscape is partially a **performance**, where perception often trumps substance. It presumes readers and reviewers will recognize the baseline's name but not its specific limitations, creating a misleading impression of progress.
*   **Implications & Connection to Broader Thinking:** Paxton's framing highlights a critical dysfunction in academic and industry AI research: the incentive to **publish eye-catching results** can override the incentive to produce genuinely comparative, rigorous science. It connects to a broader skepticism about how research is marketed, suggesting that the "state-of-the-art" is often a carefully constructed narrative rather than an objective milestone. The use of Octo as the named example serves as a direct case study in how a model's media footprint can be leveraged by others for strategic gain, regardless of its technical robustness.

## Related Concepts

- [[Cherry-picking Benchmarks]]
- [[Comparison Against Best Methods]]
- [[Low Robotics Benchmarking Standards]]